{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPdF8Ff472aiWVczCQV6mTb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sinarazi/final_project/blob/main/final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi --query-gpu=gpu_name,driver_version,memory.total --format=csv"
      ],
      "metadata": {
        "id": "g8F8PiwERxpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Requirments**"
      ],
      "metadata": {
        "id": "UaBbBXUYV4gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tensorflow==2.2.0\n",
        "! pip install keras==2.3.1\n",
        "! pip install scikit-image==0.16.2\n",
        "! pip install h5py==2.10.0"
      ],
      "metadata": {
        "id": "hXYloVD7V_AD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Libraries**"
      ],
      "metadata": {
        "id": "5BExODCCWD7C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "v3ZIbvenVCIT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import datetime\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "from imgaug import augmenters as iaa\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify the libraries' versions"
      ],
      "metadata": {
        "id": "8d3JcYXFWP89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsaqCTEjWUB8",
        "outputId": "c858e439-3c93-4bf8-9323-d5c6d5e07d6d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cloning the essential files"
      ],
      "metadata": {
        "id": "Nwfu2QniWW8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/ahmedfgad/Mask-RCNN-TF2.git"
      ],
      "metadata": {
        "id": "qz-lwvh1WWnH",
        "outputId": "d653058e-526c-4de6-cc9e-4336ed1c2bba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Mask-RCNN-TF2'...\n",
            "remote: Enumerating objects: 1434, done.\u001b[K\n",
            "remote: Total 1434 (delta 0), reused 0 (delta 0), pack-reused 1434\u001b[K\n",
            "Receiving objects: 100% (1434/1434), 144.53 MiB | 13.97 MiB/s, done.\n",
            "Resolving deltas: 100% (803/803), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling the Kaggle "
      ],
      "metadata": {
        "id": "QxNWpBH3WmrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "kWKz4wkpWq10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading the dataset from kaggle"
      ],
      "metadata": {
        "id": "nT0vZ-2aWvAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions download -c data-science-bowl-2018"
      ],
      "metadata": {
        "id": "_qI76VcfWsUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip <data-science-bowl-2018>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnqocRdVW4tN",
        "outputId": "5e4b4217-93f6-464b-8e58-918af81ca1eb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 0: syntax error near unexpected token `newline'\n",
            "/bin/bash: -c: line 0: ` unzip <data-science-bowl-2018>'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/stage1_train.zip\" -d \"/content/stage1_train\"\n",
        "!unzip \"/content/stage1_test.zip\" -d \"/content/stage1_test\""
      ],
      "metadata": {
        "id": "aeYghBW0W75I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading the pretrainded model of coco"
      ],
      "metadata": {
        "id": "omAqCjVoXPIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, zipfile, io\n",
        "#The copied URL goes here ->\n",
        "url = 'https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "# z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "# z.extractall()"
      ],
      "metadata": {
        "id": "h0h6zA5VXMVY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paths"
      ],
      "metadata": {
        "id": "rwHP2OXKY-5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"/content/\")\n",
        "# Path to trained weights file\n",
        "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "# Save submission files here\n",
        "RESULTS_DIR = os.path.join(ROOT_DIR, \"results/nucleus/\")"
      ],
      "metadata": {
        "id": "n_D7w1DzZAHp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a variety of images to surve as a validation set.\n",
        "VAL_IMAGE_IDS = [\n",
        "    \"0c2550a23b8a0f29a7575de8c61690d3c31bc897dd5ba66caec201d201a278c2\",\n",
        "    \"92f31f591929a30e4309ab75185c96ff4314ce0a7ead2ed2c2171897ad1da0c7\",\n",
        "    \"1e488c42eb1a54a3e8412b1f12cde530f950f238d71078f2ede6a85a02168e1f\",\n",
        "    \"c901794d1a421d52e5734500c0a2a8ca84651fb93b19cec2f411855e70cae339\",\n",
        "    \"8e507d58f4c27cd2a82bee79fe27b069befd62a46fdaed20970a95a2ba819c7b\",\n",
        "    \"60cb718759bff13f81c4055a7679e81326f78b6a193a2d856546097c949b20ff\",\n",
        "    \"da5f98f2b8a64eee735a398de48ed42cd31bf17a6063db46a9e0783ac13cd844\",\n",
        "    \"9ebcfaf2322932d464f15b5662cae4d669b2d785b8299556d73fffcae8365d32\",\n",
        "    \"1b44d22643830cd4f23c9deadb0bd499fb392fb2cd9526d81547d93077d983df\",\n",
        "    \"97126a9791f0c1176e4563ad679a301dac27c59011f579e808bbd6e9f4cd1034\",\n",
        "    \"e81c758e1ca177b0942ecad62cf8d321ffc315376135bcbed3df932a6e5b40c0\",\n",
        "    \"f29fd9c52e04403cd2c7d43b6fe2479292e53b2f61969d25256d2d2aca7c6a81\",\n",
        "    \"0ea221716cf13710214dcd331a61cea48308c3940df1d28cfc7fd817c83714e1\",\n",
        "    \"3ab9cab6212fabd723a2c5a1949c2ded19980398b56e6080978e796f45cbbc90\",\n",
        "    \"ebc18868864ad075548cc1784f4f9a237bb98335f9645ee727dac8332a3e3716\",\n",
        "    \"bb61fc17daf8bdd4e16fdcf50137a8d7762bec486ede9249d92e511fcb693676\",\n",
        "    \"e1bcb583985325d0ef5f3ef52957d0371c96d4af767b13e48102bca9d5351a9b\",\n",
        "    \"947c0d94c8213ac7aaa41c4efc95d854246550298259cf1bb489654d0e969050\",\n",
        "    \"cbca32daaae36a872a11da4eaff65d1068ff3f154eedc9d3fc0c214a4e5d32bd\",\n",
        "    \"f4c4db3df4ff0de90f44b027fc2e28c16bf7e5c75ea75b0a9762bbb7ac86e7a3\",\n",
        "    \"4193474b2f1c72f735b13633b219d9cabdd43c21d9c2bb4dfc4809f104ba4c06\",\n",
        "    \"f73e37957c74f554be132986f38b6f1d75339f636dfe2b681a0cf3f88d2733af\",\n",
        "    \"a4c44fc5f5bf213e2be6091ccaed49d8bf039d78f6fbd9c4d7b7428cfcb2eda4\",\n",
        "    \"cab4875269f44a701c5e58190a1d2f6fcb577ea79d842522dcab20ccb39b7ad2\",\n",
        "    \"8ecdb93582b2d5270457b36651b62776256ade3aaa2d7432ae65c14f07432d49\",\n",
        "]\n"
      ],
      "metadata": {
        "id": "WiZahzREZV9J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from shutil import copyfile, move\n",
        "move('/content/stage1_test', '/content/datasets')\n",
        "move('/content/stage1_train', '/content/datasets')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FzxTZ5NEa_1t",
        "outputId": "058d3b18-ccd3-4d53-b763-907f06e45491"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/datasets/stage1_train'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = '/content/datasets/stage1_train'\n",
        "test_data = '/content/datasets/stage1_test'"
      ],
      "metadata": {
        "id": "jF4TGfYh6sxG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Mask RCNN"
      ],
      "metadata": {
        "id": "WE0tbq_TZi6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import utils\n",
        "from mrcnn import model as modellib\n",
        "from mrcnn import visualize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQJmIs5RZhqG",
        "outputId": "087af577-b63c-4c57-ac48-abc86edcd2a5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configurations"
      ],
      "metadata": {
        "id": "UD3pxqDYZscA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NucleusConfig(Config):\n",
        "    \"\"\"Configuration for training on the nucleus segmentation dataset.\"\"\"\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"nucleus\"\n",
        "\n",
        "    # Adjust depending on your GPU memory\n",
        "    IMAGES_PER_GPU = 6\n",
        "\n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 1  # Background + nucleus\n",
        "\n",
        "    # Number of training and validation steps per epoch\n",
        "    STEPS_PER_EPOCH = (657 - len(VAL_IMAGE_IDS)) // IMAGES_PER_GPU\n",
        "    VALIDATION_STEPS = max(1, len(VAL_IMAGE_IDS) // IMAGES_PER_GPU)\n",
        "\n",
        "    # Don't exclude based on confidence. Since we have two classes\n",
        "    # then 0.5 is the minimum anyway as it picks between nucleus and BG\n",
        "    DETECTION_MIN_CONFIDENCE = 0\n",
        "\n",
        "    # Backbone network architecture\n",
        "    # Supported values are: resnet50, resnet101\n",
        "    BACKBONE = \"resnet50\"\n",
        "\n",
        "    # Input image resizing\n",
        "    # Random crops of size 512x512\n",
        "    IMAGE_RESIZE_MODE = \"crop\"\n",
        "    IMAGE_MIN_DIM = 512\n",
        "    IMAGE_MAX_DIM = 512\n",
        "    IMAGE_MIN_SCALE = 2.0\n",
        "\n",
        "    # Length of square anchor side in pixels\n",
        "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)\n",
        "\n",
        "    # ROIs kept after non-maximum supression (training and inference)\n",
        "    POST_NMS_ROIS_TRAINING = 1000\n",
        "    POST_NMS_ROIS_INFERENCE = 2000\n",
        "\n",
        "    # Non-max suppression threshold to filter RPN proposals.\n",
        "    # You can increase this during training to generate more propsals.\n",
        "    RPN_NMS_THRESHOLD = 0.9\n",
        "\n",
        "    # How many anchors per image to use for RPN training\n",
        "    RPN_TRAIN_ANCHORS_PER_IMAGE = 64\n",
        "\n",
        "    # Image mean (RGB)\n",
        "    MEAN_PIXEL = np.array([43.53, 39.56, 48.22])\n",
        "\n",
        "    # If enabled, resizes instance masks to a smaller size to reduce\n",
        "    # memory load. Recommended when using high-resolution images.\n",
        "    USE_MINI_MASK = True\n",
        "    MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask\n",
        "\n",
        "    # Number of ROIs per image to feed to classifier/mask heads\n",
        "    # The Mask RCNN paper uses 512 but often the RPN doesn't generate\n",
        "    # enough positive proposals to fill this and keep a positive:negative\n",
        "    # ratio of 1:3. You can increase the number of proposals by adjusting\n",
        "    # the RPN NMS threshold.\n",
        "    TRAIN_ROIS_PER_IMAGE = 128\n",
        "\n",
        "    # Maximum number of ground truth instances to use in one image\n",
        "    MAX_GT_INSTANCES = 200\n",
        "\n",
        "    # Max number of final detections per image\n",
        "    DETECTION_MAX_INSTANCES = 400\n"
      ],
      "metadata": {
        "id": "CJ_SRKdoZtS1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NucleusInferenceConfig(NucleusConfig):\n",
        "    # Set batch size to 1 to run one image at a time\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    # Don't resize imager for inferencing\n",
        "    IMAGE_RESIZE_MODE = \"pad64\"\n",
        "    # Non-max suppression threshold to filter RPN proposals.\n",
        "    # You can increase this during training to generate more propsals.\n",
        "    RPN_NMS_THRESHOLD = 0.7"
      ],
      "metadata": {
        "id": "AAYiZjh2Zz0J"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "KZx3XyAyZ157"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NucleusDataset(utils.Dataset):\n",
        "\n",
        "    def load_nucleus(self, dataset_dir, subset):\n",
        "        \"\"\"Load a subset of the nuclei dataset.\n",
        "\n",
        "        dataset_dir: Root directory of the dataset\n",
        "        subset: Subset to load. Either the name of the sub-directory,\n",
        "                such as stage1_train, stage1_test, ...etc. or, one of:\n",
        "                * train: stage1_train excluding validation images\n",
        "                * val: validation images from VAL_IMAGE_IDS\n",
        "        \"\"\"\n",
        "        # Add classes. We have one class.\n",
        "        # Naming the dataset nucleus, and the class nucleus\n",
        "        self.add_class(\"nucleus\", 1, \"nucleus\")\n",
        "\n",
        "        # Which subset?\n",
        "        # \"val\": use hard-coded list above\n",
        "        # \"train\": use data from stage1_train minus the hard-coded list above\n",
        "        # else: use the data from the specified sub-directory\n",
        "        assert subset in [\"train\", \"val\", \"stage1_train\", \"stage1_test\", \"stage2_test\"]\n",
        "        subset_dir = \"stage1_train\" if subset in [\"train\", \"val\"] else subset\n",
        "        dataset_dir = os.path.join(dataset_dir, subset_dir)\n",
        "        if subset == \"val\":\n",
        "            image_ids = VAL_IMAGE_IDS\n",
        "        else:\n",
        "            # Get image ids from directory names\n",
        "            image_ids = next(os.walk(dataset_dir))[1]\n",
        "            if subset == \"train\":\n",
        "                image_ids = list(set(image_ids) - set(VAL_IMAGE_IDS))\n",
        "\n",
        "        # Add images\n",
        "        for image_id in image_ids:\n",
        "            self.add_image(\n",
        "                \"nucleus\",\n",
        "                image_id=image_id,\n",
        "                path=os.path.join(dataset_dir, image_id, \"images/{}.png\".format(image_id)))\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\"Generate instance masks for an image.\n",
        "       Returns:\n",
        "        masks: A bool array of shape [height, width, instance count] with\n",
        "            one mask per instance.\n",
        "        class_ids: a 1D array of class IDs of the instance masks.\n",
        "        \"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        # Get mask directory from image path\n",
        "        mask_dir = os.path.join(os.path.dirname(os.path.dirname(info['path'])), \"masks\")\n",
        "\n",
        "        # Read mask files from .png image\n",
        "        mask = []\n",
        "        for f in next(os.walk(mask_dir))[2]:\n",
        "            if f.endswith(\".png\"):\n",
        "                m = skimage.io.imread(os.path.join(mask_dir, f)).astype(np.bool)\n",
        "                mask.append(m)\n",
        "        mask = np.stack(mask, axis=-1)\n",
        "        # Return mask, and array of class IDs of each instance. Since we have\n",
        "        # one class ID, we return an array of ones\n",
        "        return mask, np.ones([mask.shape[-1]], dtype=np.int32)\n",
        "\n",
        "    def image_reference(self, image_id):\n",
        "        \"\"\"Return the path of the image.\"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"nucleus\":\n",
        "            return info[\"id\"]\n",
        "        else:\n",
        "            super(self.__class__, self).image_reference(image_id)"
      ],
      "metadata": {
        "id": "nTAyf9ElZ2ss"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rle_encode(mask):\n",
        "    \"\"\"Encodes a mask in Run Length Encoding (RLE).\n",
        "    Returns a string of space-separated values.\n",
        "    \"\"\"\n",
        "    assert mask.ndim == 2, \"Mask must be of shape [Height, Width]\"\n",
        "    # Flatten it column wise\n",
        "    m = mask.T.flatten()\n",
        "    # Compute gradient. Equals 1 or -1 at transition points\n",
        "    g = np.diff(np.concatenate([[0], m, [0]]), n=1)\n",
        "    # 1-based indicies of transition points (where gradient != 0)\n",
        "    rle = np.where(g != 0)[0].reshape([-1, 2]) + 1\n",
        "    # Convert second index in each pair to lenth\n",
        "    rle[:, 1] = rle[:, 1] - rle[:, 0]\n",
        "    return \" \".join(map(str, rle.flatten()))\n",
        "\n",
        "\n",
        "def rle_decode(rle, shape):\n",
        "    \"\"\"Decodes an RLE encoded list of space separated\n",
        "    numbers and returns a binary mask.\"\"\"\n",
        "    rle = list(map(int, rle.split()))\n",
        "    rle = np.array(rle, dtype=np.int32).reshape([-1, 2])\n",
        "    rle[:, 1] += rle[:, 0]\n",
        "    rle -= 1\n",
        "    mask = np.zeros([shape[0] * shape[1]], np.bool)\n",
        "    for s, e in rle:\n",
        "        assert 0 <= s < mask.shape[0]\n",
        "        assert 1 <= e <= mask.shape[0], \"shape: {}  s {}  e {}\".format(shape, s, e)\n",
        "        mask[s:e] = 1\n",
        "    # Reshape and transpose\n",
        "    mask = mask.reshape([shape[1], shape[0]]).T\n",
        "    return mask\n",
        "\n",
        "\n",
        "def mask_to_rle(image_id, mask, scores):\n",
        "    \"Encodes instance masks to submission format.\"\n",
        "    assert mask.ndim == 3, \"Mask must be [H, W, count]\"\n",
        "    # If mask is empty, return line with image ID only\n",
        "    if mask.shape[-1] == 0:\n",
        "        return \"{},\".format(image_id)\n",
        "    # Remove mask overlaps\n",
        "    # Multiply each instance mask by its score order\n",
        "    # then take the maximum across the last dimension\n",
        "    order = np.argsort(scores)[::-1] + 1  # 1-based descending\n",
        "    mask = np.max(mask * np.reshape(order, [1, 1, -1]), -1)\n",
        "    # Loop over instance masks\n",
        "    lines = []\n",
        "    for o in order:\n",
        "        m = np.where(mask == o, 1, 0)\n",
        "        # Skip if empty\n",
        "        if m.sum() == 0.0:\n",
        "            continue\n",
        "        rle = rle_encode(m)\n",
        "        lines.append(\"{}, {}\".format(image_id, rle))\n",
        "    return \"\\n\".join(lines)"
      ],
      "metadata": {
        "id": "yjO7J0pF3ez7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "48WMNEczZ-n-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataset_dir, subset):\n",
        "    \"\"\"Train the model.\"\"\"\n",
        "    # Training dataset.\n",
        "    dataset_train = NucleusDataset()\n",
        "    dataset_train.load_nucleus(dataset_dir, subset)\n",
        "    dataset_train.prepare()\n",
        "\n",
        "    # Validation dataset\n",
        "    dataset_val = NucleusDataset()\n",
        "    dataset_val.load_nucleus(dataset_dir, \"val\")\n",
        "    dataset_val.prepare()\n",
        "\n",
        "    # Image augmentation\n",
        "    # http://imgaug.readthedocs.io/en/latest/source/augmenters.html\n",
        "    augmentation = iaa.SomeOf((0, 2), [\n",
        "        iaa.Fliplr(0.5),\n",
        "        iaa.Flipud(0.5),\n",
        "        iaa.OneOf([iaa.Affine(rotate=90),\n",
        "                   iaa.Affine(rotate=180),\n",
        "                   iaa.Affine(rotate=270)]),\n",
        "        iaa.Multiply((0.8, 1.5)),\n",
        "        iaa.GaussianBlur(sigma=(0.0, 5.0))\n",
        "    ])\n",
        "\n",
        "    # *** This training schedule is an example. Update to your needs ***\n",
        "\n",
        "    # If starting from imagenet, train heads only for a bit\n",
        "    # since they have random weights\n",
        "    # print(\"Train network heads\")\n",
        "    # model.train(dataset_train, dataset_val,\n",
        "    #             learning_rate=config.LEARNING_RATE,\n",
        "    #             epochs=20,\n",
        "    #             augmentation=augmentation,\n",
        "    #             layers='heads')\n",
        "\n",
        "    print(\"Train all layers\")\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=config.LEARNING_RATE,\n",
        "                epochs=10,\n",
        "                augmentation=augmentation,\n",
        "                layers='all')\n"
      ],
      "metadata": {
        "id": "pgv7ZmJbZ_tr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = '/content/datasets/'\n",
        "subset = 'stage1_train'"
      ],
      "metadata": {
        "id": "b-iardVp7ckD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate arguments\n",
        "\n",
        "config = NucleusConfig()\n",
        "\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=RESULTS_DIR)\n",
        "\n",
        "weights_path = COCO_WEIGHTS_PATH\n",
        "weights_path = model.get_imagenet_weights()\n",
        "\n",
        "# Load weights\n",
        "model.load_weights(weights_path, by_name=True, exclude=[\n",
        "    \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
        "    \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "model.load_weights(weights_path, by_name=True)\n",
        "\n",
        "train(model, dataset, subset)\n",
        "config.display()"
      ],
      "metadata": {
        "id": "uPBx8Uq-HcSF",
        "outputId": "35da8bc8-ecb9-4750-f7e3-2a9c1f423510",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train all layers\n",
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: //logdir//train/mask_rcnn_nucleus_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "conv1                  (Conv2D)\n",
            "bn_conv1               (BatchNorm)\n",
            "res2a_branch2a         (Conv2D)\n",
            "bn2a_branch2a          (BatchNorm)\n",
            "res2a_branch2b         (Conv2D)\n",
            "bn2a_branch2b          (BatchNorm)\n",
            "res2a_branch2c         (Conv2D)\n",
            "res2a_branch1          (Conv2D)\n",
            "bn2a_branch2c          (BatchNorm)\n",
            "bn2a_branch1           (BatchNorm)\n",
            "res2b_branch2a         (Conv2D)\n",
            "bn2b_branch2a          (BatchNorm)\n",
            "res2b_branch2b         (Conv2D)\n",
            "bn2b_branch2b          (BatchNorm)\n",
            "res2b_branch2c         (Conv2D)\n",
            "bn2b_branch2c          (BatchNorm)\n",
            "res2c_branch2a         (Conv2D)\n",
            "bn2c_branch2a          (BatchNorm)\n",
            "res2c_branch2b         (Conv2D)\n",
            "bn2c_branch2b          (BatchNorm)\n",
            "res2c_branch2c         (Conv2D)\n",
            "bn2c_branch2c          (BatchNorm)\n",
            "res3a_branch2a         (Conv2D)\n",
            "bn3a_branch2a          (BatchNorm)\n",
            "res3a_branch2b         (Conv2D)\n",
            "bn3a_branch2b          (BatchNorm)\n",
            "res3a_branch2c         (Conv2D)\n",
            "res3a_branch1          (Conv2D)\n",
            "bn3a_branch2c          (BatchNorm)\n",
            "bn3a_branch1           (BatchNorm)\n",
            "res3b_branch2a         (Conv2D)\n",
            "bn3b_branch2a          (BatchNorm)\n",
            "res3b_branch2b         (Conv2D)\n",
            "bn3b_branch2b          (BatchNorm)\n",
            "res3b_branch2c         (Conv2D)\n",
            "bn3b_branch2c          (BatchNorm)\n",
            "res3c_branch2a         (Conv2D)\n",
            "bn3c_branch2a          (BatchNorm)\n",
            "res3c_branch2b         (Conv2D)\n",
            "bn3c_branch2b          (BatchNorm)\n",
            "res3c_branch2c         (Conv2D)\n",
            "bn3c_branch2c          (BatchNorm)\n",
            "res3d_branch2a         (Conv2D)\n",
            "bn3d_branch2a          (BatchNorm)\n",
            "res3d_branch2b         (Conv2D)\n",
            "bn3d_branch2b          (BatchNorm)\n",
            "res3d_branch2c         (Conv2D)\n",
            "bn3d_branch2c          (BatchNorm)\n",
            "res4a_branch2a         (Conv2D)\n",
            "bn4a_branch2a          (BatchNorm)\n",
            "res4a_branch2b         (Conv2D)\n",
            "bn4a_branch2b          (BatchNorm)\n",
            "res4a_branch2c         (Conv2D)\n",
            "res4a_branch1          (Conv2D)\n",
            "bn4a_branch2c          (BatchNorm)\n",
            "bn4a_branch1           (BatchNorm)\n",
            "res4b_branch2a         (Conv2D)\n",
            "bn4b_branch2a          (BatchNorm)\n",
            "res4b_branch2b         (Conv2D)\n",
            "bn4b_branch2b          (BatchNorm)\n",
            "res4b_branch2c         (Conv2D)\n",
            "bn4b_branch2c          (BatchNorm)\n",
            "res4c_branch2a         (Conv2D)\n",
            "bn4c_branch2a          (BatchNorm)\n",
            "res4c_branch2b         (Conv2D)\n",
            "bn4c_branch2b          (BatchNorm)\n",
            "res4c_branch2c         (Conv2D)\n",
            "bn4c_branch2c          (BatchNorm)\n",
            "res4d_branch2a         (Conv2D)\n",
            "bn4d_branch2a          (BatchNorm)\n",
            "res4d_branch2b         (Conv2D)\n",
            "bn4d_branch2b          (BatchNorm)\n",
            "res4d_branch2c         (Conv2D)\n",
            "bn4d_branch2c          (BatchNorm)\n",
            "res4e_branch2a         (Conv2D)\n",
            "bn4e_branch2a          (BatchNorm)\n",
            "res4e_branch2b         (Conv2D)\n",
            "bn4e_branch2b          (BatchNorm)\n",
            "res4e_branch2c         (Conv2D)\n",
            "bn4e_branch2c          (BatchNorm)\n",
            "res4f_branch2a         (Conv2D)\n",
            "bn4f_branch2a          (BatchNorm)\n",
            "res4f_branch2b         (Conv2D)\n",
            "bn4f_branch2b          (BatchNorm)\n",
            "res4f_branch2c         (Conv2D)\n",
            "bn4f_branch2c          (BatchNorm)\n",
            "res5a_branch2a         (Conv2D)\n",
            "bn5a_branch2a          (BatchNorm)\n",
            "res5a_branch2b         (Conv2D)\n",
            "bn5a_branch2b          (BatchNorm)\n",
            "res5a_branch2c         (Conv2D)\n",
            "res5a_branch1          (Conv2D)\n",
            "bn5a_branch2c          (BatchNorm)\n",
            "bn5a_branch1           (BatchNorm)\n",
            "res5b_branch2a         (Conv2D)\n",
            "bn5b_branch2a          (BatchNorm)\n",
            "res5b_branch2b         (Conv2D)\n",
            "bn5b_branch2b          (BatchNorm)\n",
            "res5b_branch2c         (Conv2D)\n",
            "bn5b_branch2c          (BatchNorm)\n",
            "res5c_branch2a         (Conv2D)\n",
            "bn5c_branch2a          (BatchNorm)\n",
            "res5c_branch2b         (Conv2D)\n",
            "bn5c_branch2b          (BatchNorm)\n",
            "res5c_branch2c         (Conv2D)\n",
            "bn5c_branch2c          (BatchNorm)\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... can't pickle _thread.RLock objects\n",
            "Epoch 1/10\n",
            " 36/105 [=========>....................] - ETA: 5:54 - loss: 3.1541"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the weights\n",
        "model.save(\"mrcnn_model.h5\")\n",
        "tf.keras.models.save_model()\n",
        "# Save the weights using the `checkpoint_path` format\n",
        "model.save_weights()"
      ],
      "metadata": {
        "id": "MaNZFopk9eC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect(model, dataset_dir, subset):\n",
        "    \"\"\"Run detection on images in the given directory.\"\"\"\n",
        "    print(\"Running on {}\".format(dataset_dir))\n",
        "\n",
        "    # Create directory\n",
        "    if not os.path.exists(RESULTS_DIR):\n",
        "        os.makedirs(RESULTS_DIR)\n",
        "    submit_dir = \"submit_{:%Y%m%dT%H%M%S}\".format(datetime.datetime.now())\n",
        "    submit_dir = os.path.join(RESULTS_DIR, submit_dir)\n",
        "    os.makedirs(submit_dir)\n",
        "\n",
        "    # Read dataset\n",
        "    dataset = NucleusDataset()\n",
        "    dataset.load_nucleus(dataset_dir, subset)\n",
        "    dataset.prepare()\n",
        "    # Load over images\n",
        "    submission = []\n",
        "    for image_id in dataset.image_ids:\n",
        "        # Load image and run detection\n",
        "        image = dataset.load_image(image_id)\n",
        "        # Detect objects\n",
        "        r = model.detect([image], verbose=0)[0]\n",
        "        # Encode image to RLE. Returns a string of multiple lines\n",
        "        source_id = dataset.image_info[image_id][\"id\"]\n",
        "        rle = mask_to_rle(source_id, r[\"masks\"], r[\"scores\"])\n",
        "        submission.append(rle)\n",
        "        # Save image with masks\n",
        "        visualize.display_instances(\n",
        "            image, r['rois'], r['masks'], r['class_ids'],\n",
        "            dataset.class_names, r['scores'],\n",
        "            show_bbox=False, show_mask=False,\n",
        "            title=\"Predictions\")\n",
        "        plt.savefig(\"{}/{}.png\".format(submit_dir, dataset.image_info[image_id][\"id\"]))\n",
        "\n",
        "    # Save to csv file\n",
        "    submission = \"ImageId,EncodedPixels\\n\" + \"\\n\".join(submission)\n",
        "    file_path = os.path.join(submit_dir, \"submit.csv\")\n",
        "    with open(file_path, \"w\") as f:\n",
        "        f.write(submission)\n",
        "    print(\"Saved to \", submit_dir)\n"
      ],
      "metadata": {
        "id": "vrXxb_x5aFKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = '/content/datasets/'\n",
        "subset1 = 'stage1_test'"
      ],
      "metadata": {
        "id": "26JGxymWHIKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = NucleusInferenceConfig()\n",
        "config.display()\n",
        "detect(model, dataset, subset1)"
      ],
      "metadata": {
        "id": "H5CEotk_GekP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}