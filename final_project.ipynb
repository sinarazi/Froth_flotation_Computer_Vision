{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN4XzIx3IZyl32RJIlD57fL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sinarazi/final_project/blob/main/final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Libraries**"
      ],
      "metadata": {
        "id": "5BExODCCWD7C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "v3ZIbvenVCIT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import datetime\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "from imgaug import augmenters as iaa\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Requirments**"
      ],
      "metadata": {
        "id": "UaBbBXUYV4gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tensorflow==2.2.0\n",
        "! pip install keras==2.3.1\n",
        "! pip install scikit-image==0.16.2\n",
        "! pip install h5py==2.10.0"
      ],
      "metadata": {
        "id": "hXYloVD7V_AD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify the libraries' versions"
      ],
      "metadata": {
        "id": "8d3JcYXFWP89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsaqCTEjWUB8",
        "outputId": "394cf500-3a4f-4a5d-fcc2-d1ce8d80d020"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cloning the essential files"
      ],
      "metadata": {
        "id": "Nwfu2QniWW8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/ahmedfgad/Mask-RCNN-TF2.git"
      ],
      "metadata": {
        "id": "qz-lwvh1WWnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling the Kaggle "
      ],
      "metadata": {
        "id": "QxNWpBH3WmrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "kWKz4wkpWq10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading the dataset from kaggle"
      ],
      "metadata": {
        "id": "nT0vZ-2aWvAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions download -c data-science-bowl-2018"
      ],
      "metadata": {
        "id": "_qI76VcfWsUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip <data-science-bowl-2018>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnqocRdVW4tN",
        "outputId": "522601a0-34d6-474f-d463-11e52c2d6d0f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 0: syntax error near unexpected token `newline'\n",
            "/bin/bash: -c: line 0: ` unzip <data-science-bowl-2018>'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/stage1_train.zip\" -d \"/content/stage1_train\"\n",
        "!unzip \"/content/stage1_test.zip\" -d \"/content/stage1_test\""
      ],
      "metadata": {
        "id": "aeYghBW0W75I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading the pretrainded model of coco"
      ],
      "metadata": {
        "id": "omAqCjVoXPIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, zipfile, io\n",
        "#The copied URL goes here ->\n",
        "r = requests.get( 'https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5') \n",
        "# z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "# z.extractall()"
      ],
      "metadata": {
        "id": "h0h6zA5VXMVY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Path"
      ],
      "metadata": {
        "id": "rwHP2OXKY-5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"/content/\")\n",
        "# Path to trained weights file\n",
        "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "# through the command line argument --logs\n",
        "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "# Save submission files here\n",
        "RESULTS_DIR = os.path.join(ROOT_DIR, \"results/nucleus/\")"
      ],
      "metadata": {
        "id": "n_D7w1DzZAHp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a variety of images to surve as a validation set.\n",
        "VAL_IMAGE_IDS = [\n",
        "    \"0c2550a23b8a0f29a7575de8c61690d3c31bc897dd5ba66caec201d201a278c2\",\n",
        "    \"92f31f591929a30e4309ab75185c96ff4314ce0a7ead2ed2c2171897ad1da0c7\",\n",
        "    \"1e488c42eb1a54a3e8412b1f12cde530f950f238d71078f2ede6a85a02168e1f\",\n",
        "    \"c901794d1a421d52e5734500c0a2a8ca84651fb93b19cec2f411855e70cae339\",\n",
        "    \"8e507d58f4c27cd2a82bee79fe27b069befd62a46fdaed20970a95a2ba819c7b\",\n",
        "    \"60cb718759bff13f81c4055a7679e81326f78b6a193a2d856546097c949b20ff\",\n",
        "    \"da5f98f2b8a64eee735a398de48ed42cd31bf17a6063db46a9e0783ac13cd844\",\n",
        "    \"9ebcfaf2322932d464f15b5662cae4d669b2d785b8299556d73fffcae8365d32\",\n",
        "    \"1b44d22643830cd4f23c9deadb0bd499fb392fb2cd9526d81547d93077d983df\",\n",
        "    \"97126a9791f0c1176e4563ad679a301dac27c59011f579e808bbd6e9f4cd1034\",\n",
        "    \"e81c758e1ca177b0942ecad62cf8d321ffc315376135bcbed3df932a6e5b40c0\",\n",
        "    \"f29fd9c52e04403cd2c7d43b6fe2479292e53b2f61969d25256d2d2aca7c6a81\",\n",
        "    \"0ea221716cf13710214dcd331a61cea48308c3940df1d28cfc7fd817c83714e1\",\n",
        "    \"3ab9cab6212fabd723a2c5a1949c2ded19980398b56e6080978e796f45cbbc90\",\n",
        "    \"ebc18868864ad075548cc1784f4f9a237bb98335f9645ee727dac8332a3e3716\",\n",
        "    \"bb61fc17daf8bdd4e16fdcf50137a8d7762bec486ede9249d92e511fcb693676\",\n",
        "    \"e1bcb583985325d0ef5f3ef52957d0371c96d4af767b13e48102bca9d5351a9b\",\n",
        "    \"947c0d94c8213ac7aaa41c4efc95d854246550298259cf1bb489654d0e969050\",\n",
        "    \"cbca32daaae36a872a11da4eaff65d1068ff3f154eedc9d3fc0c214a4e5d32bd\",\n",
        "    \"f4c4db3df4ff0de90f44b027fc2e28c16bf7e5c75ea75b0a9762bbb7ac86e7a3\",\n",
        "    \"4193474b2f1c72f735b13633b219d9cabdd43c21d9c2bb4dfc4809f104ba4c06\",\n",
        "    \"f73e37957c74f554be132986f38b6f1d75339f636dfe2b681a0cf3f88d2733af\",\n",
        "    \"a4c44fc5f5bf213e2be6091ccaed49d8bf039d78f6fbd9c4d7b7428cfcb2eda4\",\n",
        "    \"cab4875269f44a701c5e58190a1d2f6fcb577ea79d842522dcab20ccb39b7ad2\",\n",
        "    \"8ecdb93582b2d5270457b36651b62776256ade3aaa2d7432ae65c14f07432d49\",\n",
        "]\n"
      ],
      "metadata": {
        "id": "WiZahzREZV9J"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from shutil import copyfile, move\n",
        "move('/content/stage1_test', '/content/datasets')\n",
        "move('/content/stage1_train', '/content/datasets')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FzxTZ5NEa_1t",
        "outputId": "9d9b22ef-afd6-481c-df77-fa231857080f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/datasets/stage1_train'"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Mask RCNN"
      ],
      "metadata": {
        "id": "WE0tbq_TZi6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import utils\n",
        "from mrcnn import model as modellib\n",
        "from mrcnn import visualize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQJmIs5RZhqG",
        "outputId": "77c4b90b-f273-4726-b128-942afa5fd95d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configurations"
      ],
      "metadata": {
        "id": "UD3pxqDYZscA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NucleusConfig(Config):\n",
        "    \"\"\"Configuration for training on the nucleus segmentation dataset.\"\"\"\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"nucleus\"\n",
        "\n",
        "    # Adjust depending on your GPU memory\n",
        "    IMAGES_PER_GPU = 6\n",
        "\n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 1  # Background + nucleus\n",
        "\n",
        "    # Number of training and validation steps per epoch\n",
        "    STEPS_PER_EPOCH = (657 - len(VAL_IMAGE_IDS)) // IMAGES_PER_GPU\n",
        "    VALIDATION_STEPS = max(1, len(VAL_IMAGE_IDS) // IMAGES_PER_GPU)\n",
        "\n",
        "    # Don't exclude based on confidence. Since we have two classes\n",
        "    # then 0.5 is the minimum anyway as it picks between nucleus and BG\n",
        "    DETECTION_MIN_CONFIDENCE = 0\n",
        "\n",
        "    # Backbone network architecture\n",
        "    # Supported values are: resnet50, resnet101\n",
        "    BACKBONE = \"resnet50\"\n",
        "\n",
        "    # Input image resizing\n",
        "    # Random crops of size 512x512\n",
        "    IMAGE_RESIZE_MODE = \"crop\"\n",
        "    IMAGE_MIN_DIM = 512\n",
        "    IMAGE_MAX_DIM = 512\n",
        "    IMAGE_MIN_SCALE = 2.0\n",
        "\n",
        "    # Length of square anchor side in pixels\n",
        "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)\n",
        "\n",
        "    # ROIs kept after non-maximum supression (training and inference)\n",
        "    POST_NMS_ROIS_TRAINING = 1000\n",
        "    POST_NMS_ROIS_INFERENCE = 2000\n",
        "\n",
        "    # Non-max suppression threshold to filter RPN proposals.\n",
        "    # You can increase this during training to generate more propsals.\n",
        "    RPN_NMS_THRESHOLD = 0.9\n",
        "\n",
        "    # How many anchors per image to use for RPN training\n",
        "    RPN_TRAIN_ANCHORS_PER_IMAGE = 64\n",
        "\n",
        "    # Image mean (RGB)\n",
        "    MEAN_PIXEL = np.array([43.53, 39.56, 48.22])\n",
        "\n",
        "    # If enabled, resizes instance masks to a smaller size to reduce\n",
        "    # memory load. Recommended when using high-resolution images.\n",
        "    USE_MINI_MASK = True\n",
        "    MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask\n",
        "\n",
        "    # Number of ROIs per image to feed to classifier/mask heads\n",
        "    # The Mask RCNN paper uses 512 but often the RPN doesn't generate\n",
        "    # enough positive proposals to fill this and keep a positive:negative\n",
        "    # ratio of 1:3. You can increase the number of proposals by adjusting\n",
        "    # the RPN NMS threshold.\n",
        "    TRAIN_ROIS_PER_IMAGE = 128\n",
        "\n",
        "    # Maximum number of ground truth instances to use in one image\n",
        "    MAX_GT_INSTANCES = 200\n",
        "\n",
        "    # Max number of final detections per image\n",
        "    DETECTION_MAX_INSTANCES = 400\n"
      ],
      "metadata": {
        "id": "CJ_SRKdoZtS1"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NucleusInferenceConfig(NucleusConfig):\n",
        "    # Set batch size to 1 to run one image at a time\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    # Don't resize imager for inferencing\n",
        "    IMAGE_RESIZE_MODE = \"pad64\"\n",
        "    # Non-max suppression threshold to filter RPN proposals.\n",
        "    # You can increase this during training to generate more propsals.\n",
        "    RPN_NMS_THRESHOLD = 0.7"
      ],
      "metadata": {
        "id": "AAYiZjh2Zz0J"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "KZx3XyAyZ157"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NucleusDataset(utils.Dataset):\n",
        "\n",
        "    def load_nucleus(self, dataset_dir, subset):\n",
        "        \"\"\"Load a subset of the nuclei dataset.\n",
        "\n",
        "        dataset_dir: Root directory of the dataset\n",
        "        subset: Subset to load. Either the name of the sub-directory,\n",
        "                such as stage1_train, stage1_test, ...etc. or, one of:\n",
        "                * train: stage1_train excluding validation images\n",
        "                * val: validation images from VAL_IMAGE_IDS\n",
        "        \"\"\"\n",
        "        # Add classes. We have one class.\n",
        "        # Naming the dataset nucleus, and the class nucleus\n",
        "        self.add_class(\"nucleus\", 1, \"nucleus\")\n",
        "\n",
        "        # Which subset?\n",
        "        # \"val\": use hard-coded list above\n",
        "        # \"train\": use data from stage1_train minus the hard-coded list above\n",
        "        # else: use the data from the specified sub-directory\n",
        "        assert subset in [\"train\", \"val\", \"stage1_train\", \"stage1_test\", \"stage2_test\"]\n",
        "        subset_dir = \"stage1_train\" if subset in [\"train\", \"val\"] else subset\n",
        "        dataset_dir = os.path.join(dataset_dir, subset_dir)\n",
        "        if subset == \"val\":\n",
        "            image_ids = VAL_IMAGE_IDS\n",
        "        else:\n",
        "            # Get image ids from directory names\n",
        "            image_ids = next(os.walk(dataset_dir))[1]\n",
        "            if subset == \"train\":\n",
        "                image_ids = list(set(image_ids) - set(VAL_IMAGE_IDS))\n",
        "\n",
        "        # Add images\n",
        "        for image_id in image_ids:\n",
        "            self.add_image(\n",
        "                \"nucleus\",\n",
        "                image_id=image_id,\n",
        "                path=os.path.join(dataset_dir, image_id, \"images/{}.png\".format(image_id)))\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\"Generate instance masks for an image.\n",
        "       Returns:\n",
        "        masks: A bool array of shape [height, width, instance count] with\n",
        "            one mask per instance.\n",
        "        class_ids: a 1D array of class IDs of the instance masks.\n",
        "        \"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        # Get mask directory from image path\n",
        "        mask_dir = os.path.join(os.path.dirname(os.path.dirname(info['path'])), \"masks\")\n",
        "\n",
        "        # Read mask files from .png image\n",
        "        mask = []\n",
        "        for f in next(os.walk(mask_dir))[2]:\n",
        "            if f.endswith(\".png\"):\n",
        "                m = skimage.io.imread(os.path.join(mask_dir, f)).astype(np.bool)\n",
        "                mask.append(m)\n",
        "        mask = np.stack(mask, axis=-1)\n",
        "        # Return mask, and array of class IDs of each instance. Since we have\n",
        "        # one class ID, we return an array of ones\n",
        "        return mask, np.ones([mask.shape[-1]], dtype=np.int32)\n",
        "\n",
        "    def image_reference(self, image_id):\n",
        "        \"\"\"Return the path of the image.\"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"nucleus\":\n",
        "            return info[\"id\"]\n",
        "        else:\n",
        "            super(self.__class__, self).image_reference(image_id)"
      ],
      "metadata": {
        "id": "nTAyf9ElZ2ss"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "48WMNEczZ-n-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Train the model.\"\"\"\n",
        "# Training dataset.\n",
        "dataset_train = NucleusDataset()\n",
        "dataset_train.load_nucleus('/content/datasets', 'stage1_train')\n",
        "dataset_train.prepare()\n",
        "\n",
        "# Validation dataset\n",
        "dataset_val = NucleusDataset()\n",
        "dataset_val.load_nucleus('/content/datasets', \"val\")\n",
        "dataset_val.prepare()\n",
        "\n",
        "# Image augmentation\n",
        "# http://imgaug.readthedocs.io/en/latest/source/augmenters.html\n",
        "augmentation = iaa.SomeOf((0, 2), [\n",
        "    iaa.Fliplr(0.5),\n",
        "    iaa.Flipud(0.5),\n",
        "    iaa.OneOf([iaa.Affine(rotate=90),\n",
        "                iaa.Affine(rotate=180),\n",
        "                iaa.Affine(rotate=270)]),\n",
        "    iaa.Multiply((0.8, 1.5)),\n",
        "    iaa.GaussianBlur(sigma=(0.0, 5.0))\n",
        "])\n",
        "\n",
        "# *** This training schedule is an example. Update to your needs ***\n",
        "\n",
        "# If starting from imagenet, train heads only for a bit\n",
        "# since they have random weights\n",
        "print(\"Train network heads\")\n",
        "model.train(dataset_train, dataset_val,\n",
        "            learning_rate=config.LEARNING_RATE,\n",
        "            epochs=20,\n",
        "            augmentation=augmentation,\n",
        "            layers='heads')\n",
        "\n",
        "print(\"Train all layers\")\n",
        "model.train(dataset_train, dataset_val,\n",
        "            learning_rate=config.LEARNING_RATE,\n",
        "            epochs=40,\n",
        "            augmentation=augmentation,\n",
        "            layers='all')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "pgv7ZmJbZ_tr",
        "outputId": "860dd1c2-ac4a-4dec-a3e6-f13b48829ad0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train network heads\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-63ac9f67648b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# since they have random weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train network heads\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m model.train(dataset_train, dataset_val,\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vrXxb_x5aFKK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}